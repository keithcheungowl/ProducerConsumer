{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04e1ad0-0720-43cd-9b3d-9369b13e13f7",
   "metadata": {},
   "source": [
    "# <center> Producer-consumer test </center><a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4717f4c-2827-45da-be7f-59bad33e17fd",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cca89a-e18b-4c4d-b084-ebe101f1649e",
   "metadata": {},
   "source": [
    "Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01411be9-25dd-447d-86a6-5b238219f51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:34.911324Z",
     "iopub.status.busy": "2023-09-14T20:29:34.906947Z",
     "iopub.status.idle": "2023-09-14T20:29:35.339069Z",
     "shell.execute_reply": "2023-09-14T20:29:35.339069Z",
     "shell.execute_reply.started": "2023-09-14T20:29:34.911324Z"
    }
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "import csv\n",
    "import threading\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950cd67-7710-4994-b6a5-0f0e4124e819",
   "metadata": {},
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501d42e-e02f-4a5e-8c27-b9f0d24420ce",
   "metadata": {},
   "source": [
    "Delivery: Push to a git repository A Simple Producer/Consumer Web Link Extractor\n",
    "\n",
    "The Producer\n",
    "1. The producer receives a list of URLs ­ it can be from file, command line etc; doesn't matter.\n",
    "2. It extracts the markup from each of the URLs and places this output onto some form of queue.\n",
    "\n",
    "The Consumer\n",
    "\n",
    "1. The consumer reads the queue until it is empty and the producer is no longer extracting markup.\n",
    "2. It parses the HTML and extracts and hyperlinks into a list. This list is output (file or command line) against each parsed URL.\n",
    "\n",
    "Requirements\n",
    "\n",
    "1. The producer and consumer must run concurrently.\n",
    "2. Error handling should ensure isolation ­ one bad fetch or parse should not affect processing of others.\n",
    "3. Some unit tests.\n",
    "4.  Create a GitHub account and put the project there, before sending us a link.\n",
    "\n",
    "Bonus Points\n",
    "1. URLs fetched concurrently.\n",
    "2. Trimming oldest queue entries if queue size balloons.\n",
    "3. Comprehensive test coverage.\n",
    "4. Other considerations/enhancements that we have neglected here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02e2e2-4692-4d7b-9393-2345df54242c",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47d49e-3fa1-42a7-970c-1e9558643afa",
   "metadata": {},
   "source": [
    "In this section, we'll gather together some individual components that we'll later use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544bb061-1060-425c-a985-ff650f6db829",
   "metadata": {},
   "source": [
    "Extract the URLs from a CSV into an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc8ffc0-428e-417f-9004-8aef1534ed8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:35.342691Z",
     "iopub.status.busy": "2023-09-14T20:29:35.341342Z",
     "iopub.status.idle": "2023-09-14T20:29:35.357047Z",
     "shell.execute_reply": "2023-09-14T20:29:35.357047Z",
     "shell.execute_reply.started": "2023-09-14T20:29:35.342691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.google.co.uk/', 'https://example.com/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_urls = 'URLs.csv'\n",
    "urls = []\n",
    "with open(file_urls, 'r', encoding='utf-8-sig') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        urls.append(row[0])\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a1d42-f26c-4322-bfb8-14ca280891b9",
   "metadata": {},
   "source": [
    "A function to extract all absolute URLs from a URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096fb383-0e42-4657-b2ef-09654fee797c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:35.359199Z",
     "iopub.status.busy": "2023-09-14T20:29:35.358196Z",
     "iopub.status.idle": "2023-09-14T20:29:35.846304Z",
     "shell.execute_reply": "2023-09-14T20:29:35.845282Z",
     "shell.execute_reply.started": "2023-09-14T20:29:35.359199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.iana.org/domains/example']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_absolute_links(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    urls = []\n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        href = a_tag['href']\n",
    "        if href.startswith('http'):\n",
    "            urls.append(href)\n",
    "    return urls\n",
    "\n",
    "url = 'https://example.com/'\n",
    "extract_absolute_links(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9187cc-0885-44fb-b751-f7af271023ab",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fce58-23ff-4b3b-a67d-286ade7fb769",
   "metadata": {},
   "source": [
    "Extract URLs from a CSV (URLs must begin with 'http'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c73d918-347b-468c-aada-c1b6664be416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:35.849498Z",
     "iopub.status.busy": "2023-09-14T20:29:35.848505Z",
     "iopub.status.idle": "2023-09-14T20:29:35.868231Z",
     "shell.execute_reply": "2023-09-14T20:29:35.867137Z",
     "shell.execute_reply.started": "2023-09-14T20:29:35.849498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.google.co.uk/', 'https://example.com/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_urls = 'URLs.csv'\n",
    "urls = []\n",
    "with open(file_urls, 'r', encoding='utf-8-sig') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        urls.append(row[0])\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4302af-5362-4f4b-a0b6-99456659b552",
   "metadata": {},
   "source": [
    "## Producer class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d80dbc-8346-42b6-90a3-d5393874add2",
   "metadata": {},
   "source": [
    "The `Producer` class inherits from the `Thread` class. It takes as input: (1) a `Queue`, (2) the extracted URLs. The `Queue` is the shared buffer, into which the producer adds, and from which the consumer takes.\n",
    "\n",
    "The `run()` method describes what the producer does. Namely, for a URL, it extracts the markup, and adds the URL-markup pair as an element to the queue. If the URL isn't in the correct format, then it doesn't add this to the queue, instead showing an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f0e2fb-c4a7-4afd-a15c-51b196fe2063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:35.871775Z",
     "iopub.status.busy": "2023-09-14T20:29:35.869248Z",
     "iopub.status.idle": "2023-09-14T20:29:35.883987Z",
     "shell.execute_reply": "2023-09-14T20:29:35.882461Z",
     "shell.execute_reply.started": "2023-09-14T20:29:35.871775Z"
    }
   },
   "outputs": [],
   "source": [
    "class Producer(threading.Thread):\n",
    "    def __init__(self, q, urls):\n",
    "        super().__init__()\n",
    "        self.q = q\n",
    "        self.urls = urls\n",
    "    \n",
    "    def run(self):\n",
    "        for i in range(len(self.urls)):\n",
    "            url = self.urls[i]\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                print(f'Producer: Adding {url} to the queue')\n",
    "                self.q.put([url, soup])\n",
    "            except requests.exceptions.MissingSchema as e:\n",
    "                print(f'error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5861e8af-f6ea-423a-b951-d97762deeeb9",
   "metadata": {},
   "source": [
    "## Consumer class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5124a17-d0b1-4ab4-8c5e-a2d1be45e8d1",
   "metadata": {},
   "source": [
    "The `Consumer` class also inherits from the `Thread` class. It takes the same `Queue` object as an input. \n",
    "\n",
    "Its `run()` method removes and returns an item from the queue. It attempts to extract all the absolute hyperlinks in a given URL, and puts this into a dictionary, where the keys are the URLs, and the values are the hyperlinks in that URL.\n",
    "\n",
    "The `get()` function looks for an item in the queue. If one is not found within 4 seconds, then it checks if the producer thread is still alive. If it isn't, then the producer will not do anything further, and so the consumer also has nothing further to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8cd0e88-7b34-46a8-9b95-d5f7151892d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:35.887979Z",
     "iopub.status.busy": "2023-09-14T20:29:35.886978Z",
     "iopub.status.idle": "2023-09-14T20:29:35.898995Z",
     "shell.execute_reply": "2023-09-14T20:29:35.897927Z",
     "shell.execute_reply.started": "2023-09-14T20:29:35.887979Z"
    }
   },
   "outputs": [],
   "source": [
    "class Consumer(threading.Thread):\n",
    "    def __init__(self, q):\n",
    "        super().__init__()\n",
    "        self.q = q\n",
    "        self.url2urls = {}\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                url, soup = self.q.get(timeout=4)\n",
    "                print(f'Consumer: Extracting hyperlinks in {url}')\n",
    "                urls = []\n",
    "                for a_tag in soup.find_all('a', href=True):\n",
    "                    href = a_tag['href']\n",
    "                    if href.startswith('http'):\n",
    "                        urls.append(href)\n",
    "                self.url2urls[url] = urls\n",
    "            except queue.Empty:\n",
    "                if not producer_thread.is_alive():\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d159ec-2059-4a1f-bf26-1d4d1965e181",
   "metadata": {},
   "source": [
    "The following code creates producer and consumer threads, starts them, and outputs the dictionary of URLs and hyperlinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c8661b3-9798-4978-ac55-66e24665a6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:35.906296Z",
     "iopub.status.busy": "2023-09-14T20:29:35.905280Z",
     "iopub.status.idle": "2023-09-14T20:29:40.553395Z",
     "shell.execute_reply": "2023-09-14T20:29:40.551837Z",
     "shell.execute_reply.started": "2023-09-14T20:29:35.906296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer: Adding https://www.google.co.uk/ to the queue\n",
      "Consumer: Extracting hyperlinks in https://www.google.co.uk/\n",
      "Producer: Adding https://example.com/ to the queue\n",
      "Consumer: Extracting hyperlinks in https://example.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'https://www.google.co.uk/': ['https://www.google.co.uk/imghp?hl=en&tab=wi',\n",
       "  'https://maps.google.co.uk/maps?hl=en&tab=wl',\n",
       "  'https://play.google.com/?hl=en&tab=w8',\n",
       "  'https://www.youtube.com/?tab=w1',\n",
       "  'https://news.google.com/?tab=wn',\n",
       "  'https://mail.google.com/mail/?tab=wm',\n",
       "  'https://drive.google.com/?tab=wo',\n",
       "  'https://www.google.co.uk/intl/en/about/products?tab=wh',\n",
       "  'http://www.google.co.uk/history/optout?hl=en',\n",
       "  'https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.co.uk/&ec=GAZAAQ',\n",
       "  'https://www.google.co.uk/setprefdomain?prefdom=US&sig=K_LIwOL7l082BZnfJBg3VE636h4xs%3D'],\n",
       " 'https://example.com/': ['https://www.iana.org/domains/example']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = queue.Queue(maxsize=10)\n",
    "producer_thread = Producer(q, urls)\n",
    "consumer_thread = Consumer(q)\n",
    "producer_thread.start()\n",
    "consumer_thread.start()\n",
    "producer_thread.join()\n",
    "consumer_thread.join()\n",
    "consumer_thread.url2urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d42f95-e1d5-49d1-b1bd-c9aca6be9b43",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856fa25-5542-41e6-9052-5edaf4b2f372",
   "metadata": {},
   "source": [
    "We use a bad input for a URL to show how such things get handled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a27b362-ef72-4e33-b0bc-5b96b4f204ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T20:29:40.557308Z",
     "iopub.status.busy": "2023-09-14T20:29:40.556274Z",
     "iopub.status.idle": "2023-09-14T20:29:45.222967Z",
     "shell.execute_reply": "2023-09-14T20:29:45.222445Z",
     "shell.execute_reply.started": "2023-09-14T20:29:40.557308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer: Adding https://www.google.co.uk/ to the queue\n",
      "Consumer: Extracting hyperlinks in https://www.google.co.uk/\n",
      "Producer: Adding https://example.com/ to the queue\n",
      "Consumer: Extracting hyperlinks in https://example.com/\n",
      "error: Invalid URL 'bad': No scheme supplied. Perhaps you meant https://bad?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'https://www.google.co.uk/': ['https://www.google.co.uk/imghp?hl=en&tab=wi',\n",
       "  'https://maps.google.co.uk/maps?hl=en&tab=wl',\n",
       "  'https://play.google.com/?hl=en&tab=w8',\n",
       "  'https://www.youtube.com/?tab=w1',\n",
       "  'https://news.google.com/?tab=wn',\n",
       "  'https://mail.google.com/mail/?tab=wm',\n",
       "  'https://drive.google.com/?tab=wo',\n",
       "  'https://www.google.co.uk/intl/en/about/products?tab=wh',\n",
       "  'http://www.google.co.uk/history/optout?hl=en',\n",
       "  'https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.co.uk/&ec=GAZAAQ',\n",
       "  'https://www.google.co.uk/setprefdomain?prefdom=US&sig=K_cjZ06qbYqJ9t6yguF9R1MjJrcdY%3D'],\n",
       " 'https://example.com/': ['https://www.iana.org/domains/example']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://www.google.co.uk/', 'https://example.com/', 'bad']\n",
    "q = queue.Queue(maxsize=10)\n",
    "producer_thread = Producer(q, urls)\n",
    "consumer_thread = Consumer(q)\n",
    "producer_thread.start()\n",
    "consumer_thread.start()\n",
    "producer_thread.join()\n",
    "consumer_thread.join()\n",
    "consumer_thread.url2urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6abfe9-08b8-482c-a40a-f2630c7568e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
